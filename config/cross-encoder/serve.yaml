# Cross-Encoder Serving Configuration

# Model configuration
model:
  # S3 configuration
  s3_bucket: "khai-bucket-s3-mlflow"
  model_id: "your_cross_encoder_model_id"  # Update this
  model_type: "cross-encoder"
  local_path: "/app/models/cross-encoder"

# Server configuration
server:
  host: "0.0.0.0"
  port: 8001
  workers: 1
  reload: false

# Inference settings
inference:
  batch_size: 16
  max_seq_length: 512  # Cross-encoder typically needs longer
  device: "cuda"

# Cache settings (optional)
cache:
  enable: false
  ttl: 3600
  max_size: 10000